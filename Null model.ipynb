{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a970b55-1ef6-46f7-a534-ce4cbfbc1293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Null model simulation ---\n",
      "\n",
      ">>> Gamisoyo-san Analyzing...\n",
      "  - Primary      -> Real Rate:  30.00% (vs Null Mean:   8.48%), P-value: 0.0441 (n=10)\n",
      "  - Secondary    -> Real Rate:  42.86% (vs Null Mean:   7.16%), P-value: 0.0093 (n=7)\n",
      "\n",
      ">>> Galgeun-tang Analyzing...\n",
      "  - Primary      -> Real Rate:   0.00% (vs Null Mean:   7.43%), P-value: 1.0000 (n=5)\n",
      "  - Secondary    -> Real Rate: 100.00% (vs Null Mean:   8.65%), P-value: 0.0866 (n=1)\n",
      "\n",
      ">>> Galgeunhaegi-tang Analyzing...\n",
      "  - All          -> Real Rate:  40.00% (vs Null Mean:  11.79%), P-value: 0.1093 (n=5)\n",
      "\n",
      ">>> Daeshiho-tang Analyzing...\n",
      "  - All          -> Real Rate:  66.67% (vs Null Mean:   9.23%), P-value: 0.0001 (n=12)\n",
      "\n",
      ">>> Banhabakchulcheonma-tang Analyzing...\n",
      "  - All          -> Real Rate:  60.00% (vs Null Mean:  17.17%), P-value: 0.0373 (n=5)\n",
      "\n",
      ">>> Banhasasim-tang Analyzing...\n",
      "  - All          -> Real Rate:  50.00% (vs Null Mean:   9.96%), P-value: 0.0002 (n=14)\n",
      "\n",
      ">>> Banhahubak-tang Analyzing...\n",
      "  - Primary      -> Real Rate:  66.67% (vs Null Mean:  11.10%), P-value: 0.0001 (n=9)\n",
      "  - Secondary    -> Real Rate: 100.00% (vs Null Mean:  10.13%), P-value: 0.0116 (n=2)\n",
      "\n",
      ">>> Bojungikgi-tang Analyzing...\n",
      "  - Primary      -> Real Rate:  50.00% (vs Null Mean:   8.28%), P-value: 0.0001 (n=24)\n",
      "  - Secondary    -> Real Rate: 100.00% (vs Null Mean:  11.14%), P-value: 0.0112 (n=2)\n",
      "\n",
      ">>> Saengmaek-san Analyzing...\n",
      "  - Primary      -> Real Rate:  20.00% (vs Null Mean:   2.90%), P-value: 0.1374 (n=5)\n",
      "  - Secondary    -> Real Rate: 100.00% (vs Null Mean:   3.25%), P-value: 0.0012 (n=2)\n",
      "\n",
      ">>> Sosiho-tang Analyzing...\n",
      "  - Primary      -> Real Rate:  60.00% (vs Null Mean:  10.79%), P-value: 0.0002 (n=15)\n",
      "  - Secondary    -> Real Rate: 100.00% (vs Null Mean:  18.15%), P-value: 0.1816 (n=1)\n",
      "\n",
      ">>> Socheongryong-tang Analyzing...\n",
      "  - All          -> Real Rate:  33.33% (vs Null Mean:   9.21%), P-value: 0.0414 (n=9)\n",
      "\n",
      ">>> Hyeonggaeyeongyo-tang Analyzing...\n",
      "  - All          -> Real Rate:   0.00% (vs Null Mean:  12.47%), P-value: 1.0000 (n=4)\n",
      "\n",
      ">>> Hwanglyeonhaedok-tang Analyzing...\n",
      "  - Primary      -> Real Rate:  27.27% (vs Null Mean:   4.75%), P-value: 0.0008 (n=22)\n",
      "  - Secondary    -> Real Rate:  50.00% (vs Null Mean:   4.34%), P-value: 0.0845 (n=2)\n",
      "\n",
      " all simulation complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def primary_maker(null_data_path, t_name) : \n",
    "    null_df = pd.read_excel(null_data_path)\n",
    "    primary = null_df[null_df['Prescription'] == t_name]['Primary']\n",
    "    \n",
    "    all_diseases_list = []\n",
    "    \n",
    "    # 2. 'diseases' section, delete (NaN)\n",
    "    for item in primary.dropna():\n",
    "        split_items = [name.strip() for name in item.split(',') if name.strip()]\n",
    "        all_diseases_list.extend(split_items)\n",
    "    \n",
    "    unique_diseases_primary = sorted(list(set(all_diseases_list)))\n",
    "    \n",
    "    return unique_diseases_primary\n",
    "\n",
    "def secondary_maker(null_data_path, t_name) : \n",
    "    null_df = pd.read_excel(null_data_path)\n",
    "    secondary = null_df[null_df['Prescription'] == t_name]['secondary']\n",
    "    \n",
    "    \n",
    "    all_diseases_list = []\n",
    "    \n",
    "    # 2. 'diseases' (NaN) deletion\n",
    "    for item in secondary.dropna():\n",
    "        split_items = [name.strip() for name in item.split(',') if name.strip()]\n",
    "        all_diseases_list.extend(split_items)\n",
    "    \n",
    "    # 3. (option) delete duplication of disease\n",
    "    unique_diseases_secondary = sorted(list(set(all_diseases_list)))\n",
    "    return unique_diseases_secondary\n",
    "\n",
    "# --- 1. prescription name settings ---\n",
    "prescription_names = [\n",
    "    \"Gamisoyo-san\", \"Galgeun-tang\", \"Galgeunhaegi-tang\", \"Daeshiho-tang\", \"Banhabakchulcheonma-tang\", \"Banhasasim-tang\",\n",
    "    \"Banhahubak-tang\", \"Bojungikgi-tang\", \"Saengmaek-san\",\n",
    "    \"Sosiho-tang\", \"Socheongryong-tang\", \"Hyeonggaeyeongyo-tang\",\n",
    "    \"Hwanglyeonhaedok-tang\" \n",
    "]\n",
    "\n",
    "null_data_path = r'C:\\Users\\seoku\\Desktop\\논문리비전\\supplementary file\\File S2.xlsx' \n",
    "data_path = r'C:\\Users\\seoku\\논문관련자료'\n",
    "figure_path = r'C:\\analysis_output\\histograms'\n",
    "os.makedirs(figure_path, exist_ok=True)\n",
    "\n",
    "SMDE_data_path = r'C:\\Users\\seoku\\Downloads\\SMDE.xlsx'\n",
    "df = pd.read_excel(SMDE_data_path)\n",
    "\n",
    "\n",
    "N_PERMUTATIONS = 10000\n",
    "\n",
    "# select \"primary\", \"secondary\", \"all\" key\n",
    "gold_standard_indications = {\n",
    "    \"Gamisoyo-san\": {\n",
    "        \"primary\": primary_maker(null_data_path, prescription_names[0]),\n",
    "        \"secondary\": secondary_maker(null_data_path, prescription_names[0])\n",
    "    },\n",
    "    \"Galgeun-tang\": {\"primary\": primary_maker(null_data_path, prescription_names[1]), \"secondary\": secondary_maker(null_data_path, prescription_names[1])},\n",
    "    \"Galgeunhaegi-tang\": {\"all\": primary_maker(null_data_path, prescription_names[2])},\n",
    "    \"Daeshiho-tang\": {\"all\": primary_maker(null_data_path, prescription_names[3])},\n",
    "    \"Banhabakchulcheonma-tang\": {\"all\": primary_maker(null_data_path, prescription_names[4])},\n",
    "    \"Banhasasim-tang\": {\"all\": primary_maker(null_data_path, prescription_names[5])},\n",
    "    \"Banhahubak-tang\": {\"primary\": primary_maker(null_data_path, prescription_names[6]), \"secondary\": secondary_maker(null_data_path, prescription_names[6])},\n",
    "    \"Bojungikgi-tang\": {\"primary\": primary_maker(null_data_path, prescription_names[7]), \"secondary\": secondary_maker(null_data_path, prescription_names[7])},\n",
    "    \"Saengmaek-san\": {\"primary\": primary_maker(null_data_path, prescription_names[8]), \"secondary\": secondary_maker(null_data_path, prescription_names[8])},\n",
    "    \"Sosiho-tang\": {\"primary\": primary_maker(null_data_path, prescription_names[9]), \"secondary\": secondary_maker(null_data_path, prescription_names[9])},\n",
    "    \"Socheongryong-tang\": {\"all\": primary_maker(null_data_path, prescription_names[10])},\n",
    "    \"Hyeonggaeyeongyo-tang\": {\"all\": primary_maker(null_data_path, prescription_names[11])},\n",
    "    \"Hwanglyeonhaedok-tang\": {\"primary\": primary_maker(null_data_path, prescription_names[12]), \"secondary\": secondary_maker(null_data_path, prescription_names[12])}\n",
    "}\n",
    "\n",
    "# whole disease list \n",
    "universe_of_all_diseases = list(df['Field_context'])\n",
    "\n",
    "# --- 2. analyze function---\n",
    "def get_predicted_diseases(graph):\n",
    "    predicted = [node for node, data in graph.nodes(data=True) if data.get('Group') == 'disease']\n",
    "    return predicted\n",
    "\n",
    "def calculate_concordance(predicted_diseases, gold_standard_list):\n",
    "    if not gold_standard_list: return 0.0\n",
    "    matches = len(set(predicted_diseases).intersection(set(gold_standard_list)))\n",
    "    return (matches / len(gold_standard_list)) * 100\n",
    "\n",
    "#  main analyze loop \n",
    "print(\"--- Null model simulation ---\")\n",
    "\n",
    "for t_name in prescription_names:\n",
    "    print(f\"\\n>>> {t_name} Analyzing...\")\n",
    "    \n",
    "    try:\n",
    "        with open(os.path.join(data_path, t_name + \"_G.pkl\"), 'rb') as f:\n",
    "            G_real = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"!!! Warning: {t_name}_G.pkl, unable to find. skip.\")\n",
    "        continue\n",
    "\n",
    "    real_predicted_diseases = get_predicted_diseases(G_real)\n",
    "    indications = gold_standard_indications.get(t_name, {})\n",
    "    \n",
    "    num_diseases_to_predict = len(real_predicted_diseases)\n",
    "    if num_diseases_to_predict == 0:\n",
    "        print(f\"!!! {t_name}: skip simulation, no predicted disease.\")\n",
    "        continue\n",
    "\n",
    "    # make indication_types dictionary to analyze/visualize only existing data\n",
    "    indication_types = {}\n",
    "    if indications.get('primary'): indication_types['primary'] = indications['primary']\n",
    "    if indications.get('secondary'): indication_types['secondary'] = indications['secondary']\n",
    "    if indications.get('all'): indication_types['all'] = indications['all']\n",
    "\n",
    "    # analyze each indication type \n",
    "    for ind_type, gold_standard_list in indication_types.items():\n",
    "        # real concordance rate calculation\n",
    "        real_concordance = calculate_concordance(real_predicted_diseases, gold_standard_list)\n",
    "        \n",
    "        # Null model simulation\n",
    "        random_concordances = []\n",
    "        for _ in range(N_PERMUTATIONS):\n",
    "            random_predicted_diseases = random.sample(universe_of_all_diseases, k=num_diseases_to_predict)\n",
    "            random_rate = calculate_concordance(random_predicted_diseases, gold_standard_list)\n",
    "            random_concordances.append(random_rate)\n",
    "            \n",
    "        # calculating P-value and show output\n",
    "        p_value = (sum(1 for r in random_concordances if r >= real_concordance) + 1) / (N_PERMUTATIONS + 1)\n",
    "        num_gs_indications = len(gold_standard_list)\n",
    "        # add null model average value\n",
    "        null_mean_rate = pd.Series(random_concordances).mean()\n",
    "        print(f\"  - {ind_type.capitalize():<12} -> Real Rate: {real_concordance:6.2f}% (vs Null Mean: {null_mean_rate:6.2f}%), P-value: {p_value:.4f} (n={num_gs_indications})\")\n",
    "        #print(f\"  - {ind_type.capitalize()} Indications -> Real Rate: {real_concordance:.2f}%, P-value: {p_value:.4f}\")\n",
    "\n",
    "        # visualizing histogram\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(random_concordances, bins=30, color='gray', alpha=0.7, label=f'Null Distribution (n={N_PERMUTATIONS})')\n",
    "        plt.axvline(real_concordance, color='red', linestyle='--', linewidth=2, label=f'Observed Rate of real concordance ({real_concordance:.2f}%)')\n",
    "        \n",
    "        # displaying Gold Standard quantity \n",
    "        num_gs_indications = len(gold_standard_list)\n",
    "        text_to_display = f'# of Gold Standard Indications: {num_gs_indications}'\n",
    "        # add text, left-upper side\n",
    "        plt.text(0.05, 0.95, text_to_display, \n",
    "                 transform=plt.gca().transAxes, \n",
    "                 fontsize=12, \n",
    "                 verticalalignment='top', \n",
    "                 bbox=dict(boxstyle='round,pad=0.5', fc='wheat', alpha=0.5))\n",
    "        \n",
    "        plt.title(f'Null Model for {t_name} - {ind_type.capitalize()} Indications\\n(p-value = {p_value:.4f})')\n",
    "        plt.xlabel('Concordance Rate (%)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.legend()\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.6)\n",
    "        plt.savefig(os.path.join(figure_path, f'{t_name}_null_model_{ind_type}.png'))\n",
    "        plt.close()\n",
    "\n",
    "print(\"\\n all simulation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acdc434-3bf5-46ba-b972-6c4b6727d504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
